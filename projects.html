<!DOCTYPE HTML>
<html>

<head>
  <title>sean_Wu [Competitions]</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
  <link rel="stylesheet" type="text/css" href="style/style.css" title="style" />
  <link rel="icon" href="images/waves.jpg">
</head>

<body>
  <div id="main">
    <div id="header">
      <div id="logo">
        <div id="logo_text">
          <!-- class="logo_colour", allows you to change the colour of the text -->
          <h1><a href="index.html">SEAN<span class="logo_colour"> WU</span></a></h1>
          <h2>DATA, STRATEGY AND LEARNING</h2>
        </div>
      </div>
      <div id="menubar">
        <ul id="menu">
          <!-- put class="selected" in the li tag for the selected page - to highlight which page you're on -->
          <li><a href="index.html">Home</a></li>
          <li class="selected"><a href="projects.html">Projects</a></li>
          <li><a href="cooking.html">Cooking</a></li>
          <li><a href="resume.pdf" target="_blank" rel="noopener noreferrer">C.V.</a></li>
        </ul>
      </div>
    </div>
    <div id="site_content">
      <div class="sidebar">
      </div>

      <div id="content">
        <h3>Toronto Apartment-Market Analysis</h3>
        <a href="https://github.com/seanwutoronto/toronto-apartment-market-analysis">
        GitHub Link
        </a>
        <p>
          <b>Summary: data science project from start to finish</b>
          <br>
          I initially conduct an exploratory analysis on the
          <a href="https://open.toronto.ca/dataset/apartment-building-evaluation/"> 
            dataset 
          </a>
          to examine the distribution of features.
          <br>
          I cleaned the data by removing unnecessary columns and fill in null-cells 
          by KNN (tractable due to size of dataset).
          <br>
          Categorical variables are encoded.
          <br>
          Then I remove outliers based on standard deviation, and 
          add more features with polynomial augmentation.
          <br>
          Processed dataset is then normalized and split to train-test.
          <br>
          We add a predictive model utilizing a random forest regressor, 
          predicting number of floors to the general condition of the building with 86% accuracy.
          <br>
          Conduct cross-validation by k-fold split.
          <br>
          Finally, I created the visualizations for this dataset to tell a story.
          <br>
          <br>
          Here we see the distribution of apartment buildings for the GTA.
          <br>
          <img src="images/projects/property_location.png" style="width:550px;">
          <br>
          We plot a heatmap of buildings belonging to the 
          Toronto Community Housing Corporation.
          <br>
          <img src="images/projects/gov.png" style="width:550px;">
          <br>
          More visual examples in the GitHub repo.
        </p>

        <h3>Nostradamus</h3>
        <p>
          <b>Summary: algorithmic trading assisstant</b>
          <br>
          It is a collection of modules mostly all feeding to a single reinforcement 
          learning model.
          <br>
          Data collection for news articles conducted by the Aylien News API, sentiments 
          analysis done using an uncased multilingual BERT model.
          <br>
          Real time stock price data collected selectively with yfinance API 
          due to rate limits.
          <br>
          Simulations on interest rates by Monte Carlo with geometric Brownian motion
          used for bond pricing. 
          <br>
          Asset allocation for portfolio holdings simulated by Monte Carlo 
          on the Markowitz model.
          <br>
          Experiments on particle filtering, survival anaylsis, and anything I learned 
          from university or online courses.

        </p>

        <h3>Data Science Bank</h3>
        <a href="https://github.com/seanwutoronto/data-science-bank">
        GitHub Link
        </a>
        <p>
          <b>Summary: notes but in code format</b>
          <br>
          Concepts I have learned from academia or online-courses. I convert them to code 
          and store in this repo for easy access later on.
          <br>
          <!-- Notable examples: Denoising algorithms for image-data (auto-encoder), 
          for signal-data (Fourier transform), survival analysis, hyperparameters tuning,
          ...etc.
          <br>

          <br> -->
          Includes a boilerplate template on how to best approach a data science project,
          formulated and tweaked by me throughout the years.
        </p>
      </div>
    </div>
    <div id="footer">
      <span>
        <a href="mailto:seanwutoronto@gmail.com" target="_blank">
         <img src="images/email.png" style="width:60px;height:60px;"/>
        </a>
      </span>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <span>
        <a href="https://github.com/seanwutoronto" target="_blank">
         <img src="images/git.png" style="width:60px;height:60px;"/>
        </a>
      </span>
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      <span>
        <a href="https://www.linkedin.com/in/seanwutoronto/" target="_blank">
         <img src="images/linkedin.png" style="width:60px;height:60px;"/>
        </a>
      </span>
    </div>
  </div>
</body>
</html>
